{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Pipeline: Twitter-RoBERTa-Base\n",
    "\n",
    "**Objective**: Apply `cardiffnlp/twitter-roberta-base-sentiment-latest` to the Fed Speeches dataset using a standardized pipeline.\n",
    "**Methodology**:\n",
    "1. **Load Data**: Processed sentences (`data/master/fed_master_corpus.csv`).\n",
    "2. **Inference**: Classify each sentence as Hawkish, Dovish, or Neutral.\n",
    "3. **Index Calculation**: Compute Net Sentiment Index using the \"Score-based\" formula: $Index = \\frac{Dovish_{score} - Hawkish_{score}}{Total_{count}}$.\n",
    "4. **Aggregation**: Aggregate by Date/Meeting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported utilities.\n",
      "Using device: -1 (CPU) \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure project root is in path for utils import\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import custom utilities\n",
    "try:\n",
    "    from utils.utilities import calculate_net_sentiment_scores, get_sentiment_label_RoBERTa\n",
    "    print(\"Successfully imported utilities.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import Error: {e}. Please ensure 'utils' package is available.\")\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Config\n",
    "MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "INPUT_FILE = \"../data/master/fed_master_corpus.csv\"\n",
    "OUTPUT_FILE = \"../data/result/RoBERTa_Base/Twitter_RoBERTa_inference_results.csv\"\n",
    "INDEX_OUTPUT_FILE = \"../data/result/RoBERTa_Base/monthly_index_Twitter_RoBERTa.csv\"\n",
    "\n",
    "# Set Device\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"Using device: {device} ({torch.cuda.get_device_name(0) if device==0 else 'CPU'}) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7471 sentences.\n",
      "Date range: 2018-01-31 to 2024-12-18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>section</th>\n",
       "      <th>source</th>\n",
       "      <th>speaker</th>\n",
       "      <th>word_count</th>\n",
       "      <th>month_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>The manager of the System Open Market Account ...</td>\n",
       "      <td>Developments in Financial Markets</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>Domestic financial market conditions eased con...</td>\n",
       "      <td>Staff Review of Financial Situation</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>A strengthening outlook for economic growth in...</td>\n",
       "      <td>Staff Review of Financial Situation</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>U.S. equity prices, Treasury yields, and marke...</td>\n",
       "      <td>Staff Review of Financial Situation</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>In addition, the dollar depreciated broadly am...</td>\n",
       "      <td>Staff Review of Financial Situation</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  \\\n",
       "0  2018-01-31  The manager of the System Open Market Account ...   \n",
       "1  2018-01-31  Domestic financial market conditions eased con...   \n",
       "2  2018-01-31  A strengthening outlook for economic growth in...   \n",
       "3  2018-01-31  U.S. equity prices, Treasury yields, and marke...   \n",
       "4  2018-01-31  In addition, the dollar depreciated broadly am...   \n",
       "\n",
       "                               section   source speaker  word_count month_year  \n",
       "0    Developments in Financial Markets  Minutes     NaN          24    2018-01  \n",
       "1  Staff Review of Financial Situation  Minutes     NaN          11    2018-01  \n",
       "2  Staff Review of Financial Situation  Minutes     NaN          23    2018-01  \n",
       "3  Staff Review of Financial Situation  Minutes     NaN          31    2018-01  \n",
       "4  Staff Review of Financial Situation  Minutes     NaN          29    2018-01  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "print(f\"Loaded {len(df)} sentences.\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Twitter-RoBERTa-Base model: cardiffnlp/twitter-roberta-base-sentiment-latest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter-RoBERTa-Base model loaded successfully.\n",
      "Model details: RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"dtype\": \"float32\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"positive\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 0,\n",
      "    \"neutral\": 1,\n",
      "    \"positive\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Administrator\\anaconda3\\envs\\textmining\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 2. Initialize Twitter-RoBERTa-Base Model Pipeline\n",
    "print(f\"Loading Twitter-RoBERTa-Base model: {MODEL_NAME}...\")\n",
    "try:\n",
    "    nlp = pipeline(\"sentiment-analysis\", \n",
    "                   model=MODEL_NAME, \n",
    "                   tokenizer=MODEL_NAME, \n",
    "                   device=device, \n",
    "                   truncation=True, \n",
    "                   max_length=512,\n",
    "                   return_all_scores=False)\n",
    "    print(\"Twitter-RoBERTa-Base model loaded successfully.\")\n",
    "    print(f\"Model details: {nlp.model.config}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR Loading Twitter-RoBERTa-Base Model: {e}\")\n",
    "    nlp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Twitter-RoBERTa-Base inference on 7471 sentences...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e097b8d75a4414b25ea028d12ed62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/467 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter-RoBERTa-Base inference completed. Processed 7471 predictions.\n",
      "\n",
      "raw_sentiment distribution:\n",
      "raw_sentiment\n",
      "neutral     5113\n",
      "positive    1300\n",
      "negative    1058\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. Run Twitter-RoBERTa-Base Inference\n",
    "BATCH_SIZE = 16  # Smaller batch size for Twitter-RoBERTa-Base-large\n",
    "sentences = df['text'].astype(str).tolist()\n",
    "results = []\n",
    "\n",
    "if nlp:\n",
    "    print(f\"Starting Twitter-RoBERTa-Base inference on {len(sentences)} sentences...\")\n",
    "    \n",
    "    for i in tqdm(range(0, len(sentences), BATCH_SIZE)):\n",
    "        batch = sentences[i:i + BATCH_SIZE]\n",
    "        try:\n",
    "            preds = nlp(batch)\n",
    "            results.extend(preds)\n",
    "        except Exception as e:\n",
    "            print(f\"Error at batch {i}: {e}\")\n",
    "            results.extend([{'label': 'LABEL_1', 'score': 0.0}] * len(batch))  # Neutral fallback\n",
    "    \n",
    "    print(f\"Twitter-RoBERTa-Base inference completed. Processed {len(results)} predictions.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Twitter-RoBERTa-Base model not loaded. Filling with Defaults (Neutral) for testing structure.\")\n",
    "    results = [{'label': 'LABEL_1', 'score': 0.0} for _ in sentences]\n",
    "\n",
    "# Attach raw results\n",
    "df['raw_sentiment'] = [x['label'] for x in results]\n",
    "df['sentiment_score'] = [x['score'] for x in results]\n",
    "\n",
    "print(\"\\nraw_sentiment distribution:\")\n",
    "print(df['raw_sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped sentiment distribution:\n",
      "sentiment\n",
      "Neutral    5113\n",
      "Dovish     1300\n",
      "Hawkish    1058\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping examples:\n",
      "neutral → Neutral\n",
      "positive → Dovish\n",
      "negative → Hawkish\n"
     ]
    }
   ],
   "source": [
    "# 4. Map RoBERTa Labels to Fed Context\n",
    "# Using imported function: get_sentiment_label_RoBERTa\n",
    "\n",
    "df['sentiment'] = df['raw_sentiment'].apply(get_sentiment_label_RoBERTa)\n",
    "\n",
    "print(\"Mapped sentiment distribution:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "\n",
    "# Show mapping examples\n",
    "print(\"\\nLabel mapping examples:\")\n",
    "mapping_examples = df[['raw_sentiment', 'sentiment']].drop_duplicates().head(10)\n",
    "for _, row in mapping_examples.iterrows():\n",
    "    print(f\"{row['raw_sentiment']} → {row['sentiment']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped sentiment distribution:\n",
      "sentiment\n",
      "Neutral    5113\n",
      "Dovish     1300\n",
      "Hawkish    1058\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping examples:\n",
      "neutral -> Neutral\n",
      "positive -> Dovish\n",
      "negative -> Hawkish\n",
      "Monthly index calculated for 74 months\n",
      "RoBERTa sentiment range: -0.640 to 0.707\n",
      "\n",
      "Saved detailed results to ../data/result/RoBERTa_Base/Twitter_RoBERTa_inference_results.csv\n",
      "Saved monthly index to ../data/result/RoBERTa_Base/monthly_index_Twitter_RoBERTa.csv\n"
     ]
    }
   ],
   "source": [
    "# 5. Calculate Sentiment Index\n",
    "# Using score-based calculation: (Dovish_score - Hawkish_score) / count\n",
    "\n",
    "df['sentiment'] = df['raw_sentiment'].apply(get_sentiment_label_RoBERTa)\n",
    "\n",
    "print(\"Mapped sentiment distribution:\")\n",
    "print(df[\"sentiment\"].value_counts())\n",
    "\n",
    "# Show mapping examples\n",
    "print(\"\\nLabel mapping examples:\")\n",
    "mapping_examples = df[['raw_sentiment', 'sentiment']].drop_duplicates().head(10)\n",
    "for _, row in mapping_examples.iterrows():\n",
    "    print(f\"{row['raw_sentiment']} -> {row['sentiment']}\")\n",
    "\n",
    "# Calculate monthly sentiment index\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "\n",
    "# Apply score-based calculation\n",
    "monthly_index = df.groupby(\"month\", group_keys=False).apply(\n",
    "    calculate_net_sentiment_scores, include_groups=False\n",
    ").reset_index(name=\"sentiment_score\")\n",
    "\n",
    "monthly_index['month'] = monthly_index['month'].dt.to_timestamp()\n",
    "monthly_index = monthly_index.sort_values('month')\n",
    "\n",
    "print(f\"Monthly index calculated for {len(monthly_index)} months\")\n",
    "print(f\"RoBERTa sentiment range: {monthly_index['sentiment_score'].min():.3f} to {monthly_index['sentiment_score'].max():.3f}\")\n",
    "\n",
    "# Save results\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "monthly_index.to_csv(INDEX_OUTPUT_FILE, index=False)\n",
    "print(f\"\\nSaved detailed results to {OUTPUT_FILE}\")\n",
    "print(f\"Saved monthly index to {INDEX_OUTPUT_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
