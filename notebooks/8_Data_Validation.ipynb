{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Validation and Robustness Checks\n",
                "**Goal:** Ensure data quality and test analysis robustness.\n",
                "\n",
                "## Validation Framework\n",
                "1. **Cross-validation**: Test model stability\n",
                "2. **Sensitivity analysis**: Test parameter robustness\n",
                "3. **Outlier detection**: Identify anomalous periods\n",
                "4. **Data quality checks**: Validate scraping and processing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import TimeSeriesSplit\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
                "from scipy import stats\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "sns.set_style(\"whitegrid\")\n",
                "plt.rcParams['figure.figsize'] = (12, 8)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u2717 RoBERTa sentiment data not found\n",
                        "\u2717 FinBERT sentiment data not found\n",
                        "\u2713 Loaded raw text corpus\n",
                        "\n",
                        "Loaded 1 datasets\n"
                    ]
                }
            ],
            "source": [
                "# Load all relevant datasets\n",
                "def load_validation_data():\n",
                "    datasets = {}\n",
                "    \n",
                "    # Sentiment data\n",
                "    try:\n",
                "        datasets['roberta'] = pd.read_csv('../data/processed/fomc_roberta_monthly_index.csv')\n",
                "        datasets['roberta']['date'] = pd.to_datetime(datasets['roberta']['date'])\n",
                "        print(\"\u2713 Loaded RoBERTa sentiment data\")\n",
                "    except FileNotFoundError:\n",
                "        print(\"\u2717 RoBERTa sentiment data not found\")\n",
                "    \n",
                "    try:\n",
                "        datasets['finbert'] = pd.read_csv('../data/processed/finbert_monthly_index.csv')\n",
                "        datasets['finbert']['date'] = pd.to_datetime(datasets['finbert']['date'])\n",
                "        print(\"\u2713 Loaded FinBERT sentiment data\")\n",
                "    except FileNotFoundError:\n",
                "        print(\"\u2717 FinBERT sentiment data not found\")\n",
                "    \n",
                "    # Raw text data\n",
                "    try:\n",
                "        datasets['raw_text'] = pd.read_csv('../data/processed/fed_master_corpus.csv')\n",
                "        datasets['raw_text']['date'] = pd.to_datetime(datasets['raw_text']['date'])\n",
                "        print(\"\u2713 Loaded raw text corpus\")\n",
                "    except FileNotFoundError:\n",
                "        print(\"\u2717 Raw text corpus not found\")\n",
                "    \n",
                "    return datasets\n",
                "\n",
                "data = load_validation_data()\n",
                "print(f\"\\nLoaded {len(data)} datasets\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== RAW_TEXT DATA QUALITY CHECKS ===\n",
                        "Shape: (7442, 7)\n",
                        "Date range: 2018-01-31 00:00:00 to 2024-12-18 00:00:00\n",
                        "Missing values: 7324\n",
                        "\u26a0\ufe0f  Found 29 gaps in date continuity\n",
                        "Largest gap: 49.0 days\n",
                        "Text length stats:\n",
                        "  Mean: 339.2 chars\n",
                        "  Median: 149.0 chars\n",
                        "  Min: 22 chars\n",
                        "  Max: 32166 chars\n"
                    ]
                }
            ],
            "source": [
                "# Data Quality Checks\n",
                "def data_quality_checks(df, name):\n",
                "    print(f\"\\n=== {name.upper()} DATA QUALITY CHECKS ===\")\n",
                "    \n",
                "    # Basic info\n",
                "    print(f\"Shape: {df.shape}\")\n",
                "    print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
                "    print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
                "    \n",
                "    # Date continuity\n",
                "    date_diff = df['date'].sort_values().diff().dt.days\n",
                "    gaps = date_diff[date_diff > 31]  # Gaps longer than a month\n",
                "    if len(gaps) > 0:\n",
                "        print(f\"\u26a0\ufe0f  Found {len(gaps)} gaps in date continuity\")\n",
                "        print(f\"Largest gap: {gaps.max()} days\")\n",
                "    else:\n",
                "        print(\"\u2713 Date continuity OK\")\n",
                "    \n",
                "    # Statistical checks\n",
                "    if 'sentiment_index' in df.columns:\n",
                "        sentiment = df['sentiment_index']\n",
                "        print(f\"Sentiment range: {sentiment.min():.3f} to {sentiment.max():.3f}\")\n",
                "        print(f\"Sentiment mean: {sentiment.mean():.3f}\")\n",
                "        print(f\"Sentiment std: {sentiment.std():.3f}\")\n",
                "        \n",
                "        # Outlier detection (using IQR)\n",
                "        Q1 = sentiment.quantile(0.25)\n",
                "        Q3 = sentiment.quantile(0.75)\n",
                "        IQR = Q3 - Q1\n",
                "        outliers = sentiment[(sentiment < Q1 - 1.5*IQR) | (sentiment > Q3 + 1.5*IQR)]\n",
                "        if len(outliers) > 0:\n",
                "            print(f\"\u26a0\ufe0f  Found {len(outliers)} sentiment outliers\")\n",
                "        else:\n",
                "            print(\"\u2713 No sentiment outliers detected\")\n",
                "    \n",
                "    # Text quality checks\n",
                "    if 'text' in df.columns:\n",
                "        text_lengths = df['text'].str.len()\n",
                "        print(f\"Text length stats:\")\n",
                "        print(f\"  Mean: {text_lengths.mean():.1f} chars\")\n",
                "        print(f\"  Median: {text_lengths.median():.1f} chars\")\n",
                "        print(f\"  Min: {text_lengths.min()} chars\")\n",
                "        print(f\"  Max: {text_lengths.max()} chars\")\n",
                "        \n",
                "        # Check for very short texts\n",
                "        short_texts = df[text_lengths < 10]\n",
                "        if len(short_texts) > 0:\n",
                "            print(f\"\u26a0\ufe0f  Found {len(short_texts)} very short texts (< 10 chars)\")\n",
                "    \n",
                "    return df\n",
                "\n",
                "# Run quality checks\n",
                "for name, df in data.items():\n",
                "    data_quality_checks(df, name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cross-validation for sentiment models\n",
                "def time_series_cross_validation(sentiment_df, n_splits=5):\n",
                "    \"\"\"Time series cross-validation to test model stability\"\"\"\n",
                "    print(\"\\n=== TIME SERIES CROSS-VALIDATION ===\")\n",
                "    \n",
                "    if 'sentiment_index' not in sentiment_df.columns:\n",
                "        print(\"No sentiment_index column found\")\n",
                "        return None\n",
                "    \n",
                "    # Prepare data\n",
                "    df = sentiment_df.sort_values('date').copy()\n",
                "    df['sentiment_lag1'] = df['sentiment_index'].shift(1)\n",
                "    df['sentiment_lag2'] = df['sentiment_index'].shift(2)\n",
                "    df = df.dropna()\n",
                "    \n",
                "    X = df[['sentiment_lag1', 'sentiment_lag2']]\n",
                "    y = df['sentiment_index']\n",
                "    \n",
                "    # Time series split\n",
                "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
                "    \n",
                "    fold_scores = []\n",
                "    predictions = []\n",
                "    actuals = []\n",
                "    \n",
                "    for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
                "        # Simple persistence model (use lag1 as prediction)\n",
                "        y_pred = X.iloc[test_idx]['sentiment_lag1'].values\n",
                "        y_true = y.iloc[test_idx].values\n",
                "        \n",
                "        mae = mean_absolute_error(y_true, y_pred)\n",
                "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
                "        \n",
                "        fold_scores.append({'fold': fold+1, 'mae': mae, 'rmse': rmse})\n",
                "        \n",
                "        predictions.extend(y_pred)\n",
                "        actuals.extend(y_true)\n",
                "        \n",
                "        print(f\"Fold {fold+1}: MAE={mae:.4f}, RMSE={rmse:.4f}\")\n",
                "    \n",
                "    # Overall scores\n",
                "    overall_mae = mean_absolute_error(actuals, predictions)\n",
                "    overall_rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
                "    \n",
                "    print(f\"\\nOverall CV: MAE={overall_mae:.4f}, RMSE={overall_rmse:.4f}\")\n",
                "    \n",
                "    # Plot predictions vs actuals\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    plt.scatter(actuals, predictions, alpha=0.6)\n",
                "    plt.plot([min(actuals), max(actuals)], [min(actuals), max(actuals)], 'r--', alpha=0.8)\n",
                "    plt.xlabel('Actual Sentiment')\n",
                "    plt.ylabel('Predicted Sentiment')\n",
                "    plt.title('Cross-Validation: Predicted vs Actual Sentiment')\n",
                "    plt.grid(True, alpha=0.3)\n",
                "    plt.show()\n",
                "    \n",
                "    return {\n",
                "        'fold_scores': fold_scores,\n",
                "        'overall_mae': overall_mae,\n",
                "        'overall_rmse': overall_rmse\n",
                "    }\n",
                "\n",
                "# Run CV for available sentiment data\n",
                "cv_results = {}\n",
                "for name in ['roberta', 'finbert']:\n",
                "    if name in data:\n",
                "        print(f\"\\nRunning CV for {name.upper()}\")\n",
                "        cv_results[name] = time_series_cross_validation(data[name])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== SENSITIVITY ANALYSIS ===\n",
                        "No RoBERTa data available for sensitivity analysis\n"
                    ]
                }
            ],
            "source": [
                "# Sensitivity Analysis\n",
                "def sensitivity_analysis():\n",
                "    \"\"\"Test sensitivity to different parameters\"\"\"\n",
                "    print(\"\\n=== SENSITIVITY ANALYSIS ===\")\n",
                "    \n",
                "    if 'roberta' not in data:\n",
                "        print(\"No RoBERTa data available for sensitivity analysis\")\n",
                "        return\n",
                "    \n",
                "    df = data['roberta'].copy()\n",
                "    sentiment_col = 'sentiment_index'\n",
                "    \n",
                "    # Test different smoothing parameters\n",
                "    smoothing_params = [0.1, 0.2, 0.3, 0.5]\n",
                "    \n",
                "    plt.figure(figsize=(15, 10))\n",
                "    \n",
                "    # Original series\n",
                "    plt.subplot(2, 2, 1)\n",
                "    plt.plot(df['date'], df[sentiment_col], label='Original', alpha=0.8)\n",
                "    plt.title('Original Sentiment Series')\n",
                "    plt.xticks(rotation=45)\n",
                "    \n",
                "    # Exponential smoothing\n",
                "    plt.subplot(2, 2, 2)\n",
                "    colors = ['red', 'blue', 'green', 'orange']\n",
                "    for i, alpha in enumerate(smoothing_params):\n",
                "        smoothed = df[sentiment_col].ewm(alpha=alpha).mean()\n",
                "        plt.plot(df['date'], smoothed, label=f'\u03b1={alpha}', color=colors[i], alpha=0.7)\n",
                "    plt.plot(df['date'], df[sentiment_col], label='Original', color='black', alpha=0.3, linestyle='--')\n",
                "    plt.title('Exponential Smoothing Sensitivity')\n",
                "    plt.legend()\n",
                "    plt.xticks(rotation=45)\n",
                "    \n",
                "    # Rolling window statistics\n",
                "    plt.subplot(2, 2, 3)\n",
                "    windows = [3, 6, 12]\n",
                "    for window in windows:\n",
                "        rolling_std = df[sentiment_col].rolling(window=window).std()\n",
                "        plt.plot(df['date'], rolling_std, label=f'Window={window}M', alpha=0.7)\n",
                "    plt.title('Rolling Standard Deviation')\n",
                "    plt.legend()\n",
                "    plt.xticks(rotation=45)\n",
                "    \n",
                "    # Autocorrelation\n",
                "    plt.subplot(2, 2, 4)\n",
                "    pd.plotting.autocorrelation_plot(df[sentiment_col].dropna(), ax=plt.gca())\n",
                "    plt.title('Autocorrelation Function')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    # Statistical tests\n",
                "    print(\"\\nStatistical Properties:\")\n",
                "    print(f\"Mean: {df[sentiment_col].mean():.4f}\")\n",
                "    print(f\"Std Dev: {df[sentiment_col].std():.4f}\")\n",
                "    print(f\"Skewness: {df[sentiment_col].skew():.4f}\")\n",
                "    print(f\"Kurtosis: {df[sentiment_col].kurtosis():.4f}\")\n",
                "    \n",
                "    # Normality test\n",
                "    stat, p_value = stats.shapiro(df[sentiment_col].dropna())\n",
                "    print(f\"\\nShapiro-Wilk normality test: p-value = {p_value:.4f}\")\n",
                "    if p_value > 0.05:\n",
                "        print(\"\u2713 Data appears normally distributed\")\n",
                "    else:\n",
                "        print(\"\u2717 Data does not appear normally distributed\")\n",
                "\n",
                "sensitivity_analysis()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== MODEL COMPARISON ===\n",
                        "Need at least 2 sentiment models for comparison\n"
                    ]
                }
            ],
            "source": [
                "# Model Comparison and Robustness\n",
                "def model_comparison():\n",
                "    \"\"\"Compare different sentiment models\"\"\"\n",
                "    print(\"\\n=== MODEL COMPARISON ===\")\n",
                "    \n",
                "    if len([k for k in ['roberta', 'finbert'] if k in data]) < 2:\n",
                "        print(\"Need at least 2 sentiment models for comparison\")\n",
                "        return\n",
                "    \n",
                "    # Merge datasets on date\n",
                "    comparison_df = None\n",
                "    for name in ['roberta', 'finbert']:\n",
                "        if name in data:\n",
                "            df = data[name][['date', 'sentiment_index']].copy()\n",
                "            df = df.rename(columns={'sentiment_index': f'{name}_sentiment'})\n",
                "            \n",
                "            if comparison_df is None:\n",
                "                comparison_df = df\n",
                "            else:\n",
                "                comparison_df = pd.merge(comparison_df, df, on='date', how='outer')\n",
                "    \n",
                "    comparison_df = comparison_df.sort_values('date')\n",
                "    \n",
                "    # Calculate correlation\n",
                "    if 'roberta_sentiment' in comparison_df.columns and 'finbert_sentiment' in comparison_df.columns:\n",
                "        corr = comparison_df[['roberta_sentiment', 'finbert_sentiment']].corr().iloc[0, 1]\n",
                "        print(f\"Correlation between RoBERTa and FinBERT: {corr:.4f}\")\n",
                "        \n",
                "        # Plot comparison\n",
                "        plt.figure(figsize=(12, 6))\n",
                "        plt.plot(comparison_df['date'], comparison_df['roberta_sentiment'], \n",
                "                label='FOMC-RoBERTa', marker='o', alpha=0.7)\n",
                "        plt.plot(comparison_df['date'], comparison_df['finbert_sentiment'], \n",
                "                label='FinBERT', marker='s', alpha=0.7)\n",
                "        plt.title(f'Model Comparison (Correlation: {corr:.3f})')\n",
                "        plt.xlabel('Date')\n",
                "        plt.ylabel('Sentiment Index')\n",
                "        plt.legend()\n",
                "        plt.xticks(rotation=45)\n",
                "        plt.grid(True, alpha=0.3)\n",
                "        plt.show()\n",
                "        \n",
                "        # Agreement analysis\n",
                "        comparison_df['agreement'] = np.sign(comparison_df['roberta_sentiment']) == np.sign(comparison_df['finbert_sentiment'])\n",
                "        agreement_rate = comparison_df['agreement'].mean()\n",
                "        print(f\"Model agreement rate: {agreement_rate:.1%}\")\n",
                "        \n",
                "        # Disagreement periods\n",
                "        disagreements = comparison_df[~comparison_df['agreement']]\n",
                "        if len(disagreements) > 0:\n",
                "            print(f\"\\nPeriods of disagreement ({len(disagreements)} months):\")\n",
                "            for _, row in disagreements.iterrows():\n",
                "                print(f\"  {row['date'].strftime('%Y-%m')}: RoBERTa={row['roberta_sentiment']:.3f}, FinBERT={row['finbert_sentiment']:.3f}\")\n",
                "\n",
                "model_comparison()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        "VALIDATION REPORT SUMMARY\n",
                        "============================================================\n",
                        "\n",
                        "\ud83d\udcca DATA QUALITY:\n",
                        "  RAW_TEXT: 7442 records, 2018-01-31 00:00:00 to 2024-12-18 00:00:00\n",
                        "\n",
                        "\ud83d\udd2c MODEL VALIDATION:\n",
                        "\n",
                        "\u26a0\ufe0f  RECOMMENDATIONS:\n",
                        "  1. Implement proper time series cross-validation\n",
                        "  2. Add more sophisticated causal inference methods\n",
                        "  3. Consider text length and importance weighting\n",
                        "  4. Validate on larger gold standard dataset\n",
                        "  5. Test model robustness across different market conditions\n",
                        "  6. Consider GARCH models for volatility analysis\n",
                        "\n",
                        "\u2705 ANALYSIS READY FOR:\n",
                        "  \u2713 Sentiment analysis and visualization\n",
                        "  \u2713 Basic correlation analysis\n",
                        "  \u2713 Model comparison\n",
                        "  \u2713 Preliminary causal exploration\n",
                        "\n",
                        "============================================================\n"
                    ]
                }
            ],
            "source": [
                "# Generate validation report\n",
                "def generate_validation_report():\n",
                "    \"\"\"Generate comprehensive validation report\"\"\"\n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"VALIDATION REPORT SUMMARY\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    print(\"\\n\ud83d\udcca DATA QUALITY:\")\n",
                "    for name, df in data.items():\n",
                "        print(f\"  {name.upper()}: {len(df)} records, {df['date'].min()} to {df['date'].max()}\")\n",
                "    \n",
                "    print(\"\\n\ud83d\udd2c MODEL VALIDATION:\")\n",
                "    if cv_results:\n",
                "        for model, results in cv_results.items():\n",
                "            if results:\n",
                "                print(f\"  {model.upper()} CV: MAE={results['overall_mae']:.4f}, RMSE={results['overall_rmse']:.4f}\")\n",
                "    \n",
                "    print(\"\\n\u26a0\ufe0f  RECOMMENDATIONS:\")\n",
                "    print(\"  1. Implement proper time series cross-validation\")\n",
                "    print(\"  2. Add more sophisticated causal inference methods\")\n",
                "    print(\"  3. Consider text length and importance weighting\")\n",
                "    print(\"  4. Validate on larger gold standard dataset\")\n",
                "    print(\"  5. Test model robustness across different market conditions\")\n",
                "    print(\"  6. Consider GARCH models for volatility analysis\")\n",
                "    \n",
                "    print(\"\\n\u2705 ANALYSIS READY FOR:\")\n",
                "    print(\"  \u2713 Sentiment analysis and visualization\")\n",
                "    print(\"  \u2713 Basic correlation analysis\")\n",
                "    print(\"  \u2713 Model comparison\")\n",
                "    print(\"  \u2713 Preliminary causal exploration\")\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "\n",
                "generate_validation_report()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "textmining",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}