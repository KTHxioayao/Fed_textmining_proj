{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Pipeline: RoBERTa-Large\n",
    "\n",
    "**Objective**: Apply `j-hartmann/sentiment-roberta-large-english-3-classes` to the Fed Speeches dataset using a standardized pipeline.\n",
    "**Methodology**:\n",
    "1. **Load Data**: Processed sentences (`data/master/fed_master_corpus.csv`).\n",
    "2. **Inference**: Classify each sentence as Hawkish, Dovish, or Neutral.\n",
    "3. **Index Calculation**: Compute Net Sentiment Index using the \"Score-based\" formula: $Index = \\frac{Dovish_{score} - Hawkish_{score}}{Total_{count}}$.\n",
    "4. **Aggregation**: Aggregate by Date/Meeting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported utilities.\n",
      "Using device: -1 (CPU) \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure project root is in path for utils import\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import custom utilities\n",
    "try:\n",
    "    from utils.utilities import calculate_net_sentiment_scores, get_sentiment_label_RoBERTa\n",
    "    print(\"Successfully imported utilities.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import Error: {e}. Please ensure 'utils' package is available.\")\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Config\n",
    "MODEL_NAME = \"j-hartmann/sentiment-roberta-large-english-3-classes\"\n",
    "\n",
    "INPUT_FILE = \"../data/master/fed_master_corpus.csv\"\n",
    "OUTPUT_FILE = \"../data/result/RoBERTa_Large/roberta_large_inference_results.csv\"\n",
    "INDEX_OUTPUT_FILE = \"../data/result/RoBERTa_Large/monthly_index_RoBERTa_large.csv\"\n",
    "\n",
    "# Set Device\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"Using device: {device} ({torch.cuda.get_device_name(0) if device==0 else 'CPU'}) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8297 sentences.\n",
      "Date range: 2018-01-31 to 2024-12-18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>section</th>\n",
       "      <th>source</th>\n",
       "      <th>speaker</th>\n",
       "      <th>word_count</th>\n",
       "      <th>month_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>The manager of the System Open Market Account ...</td>\n",
       "      <td>Developments in Financial Markets</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>Domestic financial market conditions eased con...</td>\n",
       "      <td>Staff Review of Financial Situation</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>A strengthening outlook for economic growth in...</td>\n",
       "      <td>Staff Review of Financial Situation</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>U.S. equity prices, Treasury yields, and marke...</td>\n",
       "      <td>Staff Review of Financial Situation</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>In addition, the dollar depreciated broadly am...</td>\n",
       "      <td>Staff Review of Financial Situation</td>\n",
       "      <td>Minutes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  \\\n",
       "0  2018-01-31  The manager of the System Open Market Account ...   \n",
       "1  2018-01-31  Domestic financial market conditions eased con...   \n",
       "2  2018-01-31  A strengthening outlook for economic growth in...   \n",
       "3  2018-01-31  U.S. equity prices, Treasury yields, and marke...   \n",
       "4  2018-01-31  In addition, the dollar depreciated broadly am...   \n",
       "\n",
       "                               section   source speaker  word_count month_year  \n",
       "0    Developments in Financial Markets  Minutes     NaN          24    2018-01  \n",
       "1  Staff Review of Financial Situation  Minutes     NaN          11    2018-01  \n",
       "2  Staff Review of Financial Situation  Minutes     NaN          23    2018-01  \n",
       "3  Staff Review of Financial Situation  Minutes     NaN          31    2018-01  \n",
       "4  Staff Review of Financial Situation  Minutes     NaN          29    2018-01  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "print(f\"Loaded {len(df)} sentences.\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RoBERTa model: j-hartmann/sentiment-roberta-large-english-3-classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at j-hartmann/sentiment-roberta-large-english-3-classes were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa model loaded successfully.\n",
      "Model details: RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"negative\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"positive\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"negative\": 0,\n",
      "    \"neutral\": 1,\n",
      "    \"positive\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Administrator\\anaconda3\\envs\\textmining\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 2. Initialize RoBERTa Model Pipeline\n",
    "print(f\"Loading RoBERTa model: {MODEL_NAME}...\")\n",
    "try:\n",
    "    nlp = pipeline(\"sentiment-analysis\", \n",
    "                   model=MODEL_NAME, \n",
    "                   tokenizer=MODEL_NAME, \n",
    "                   device=device, \n",
    "                   truncation=True, \n",
    "                   max_length=512,\n",
    "                   return_all_scores=False)\n",
    "    print(\"RoBERTa model loaded successfully.\")\n",
    "    print(f\"Model details: {nlp.model.config}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR Loading RoBERTa Model: {e}\")\n",
    "    nlp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RoBERTa inference on 8297 sentences...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e926e4d44747cf8cb6948b13d1e4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa inference completed. Processed 8297 predictions.\n",
      "\n",
      "raw_sentiment distribution:\n",
      "raw_sentiment\n",
      "neutral     7876\n",
      "negative     317\n",
      "positive     104\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. Run RoBERTa Inference\n",
    "BATCH_SIZE = 16  # Smaller batch size for RoBERTa-large\n",
    "sentences = df['text'].astype(str).tolist()\n",
    "results = []\n",
    "\n",
    "if nlp:\n",
    "    print(f\"Starting RoBERTa inference on {len(sentences)} sentences...\")\n",
    "    \n",
    "    for i in tqdm(range(0, len(sentences), BATCH_SIZE)):\n",
    "        batch = sentences[i:i + BATCH_SIZE]\n",
    "        try:\n",
    "            preds = nlp(batch)\n",
    "            results.extend(preds)\n",
    "        except Exception as e:\n",
    "            print(f\"Error at batch {i}: {e}\")\n",
    "            results.extend([{'label': 'LABEL_1', 'score': 0.0}] * len(batch))  # Neutral fallback\n",
    "    \n",
    "    print(f\"RoBERTa inference completed. Processed {len(results)} predictions.\")\n",
    "    \n",
    "else:\n",
    "    print(\"RoBERTa model not loaded. Filling with Defaults (Neutral) for testing structure.\")\n",
    "    results = [{'label': 'LABEL_1', 'score': 0.0} for _ in sentences]\n",
    "\n",
    "# Attach raw results\n",
    "df['raw_sentiment'] = [x['label'] for x in results]\n",
    "df['sentiment_score'] = [x['score'] for x in results]\n",
    "\n",
    "print(\"\\nraw_sentiment distribution:\")\n",
    "print(df['raw_sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped sentiment distribution:\n",
      "sentiment\n",
      "Neutral    7876\n",
      "Dovish      317\n",
      "Hawkish     104\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping examples:\n",
      "neutral → Neutral\n",
      "positive → Hawkish\n",
      "negative → Dovish\n"
     ]
    }
   ],
   "source": [
    "# 4. Map RoBERTa Labels to Fed Context\n",
    "# Using imported function: get_sentiment_label_RoBERTa\n",
    "\n",
    "df['sentiment'] = df['raw_sentiment'].apply(get_sentiment_label_RoBERTa)\n",
    "\n",
    "print(\"Mapped sentiment distribution:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "\n",
    "# Show mapping examples\n",
    "print(\"\\nLabel mapping examples:\")\n",
    "mapping_examples = df[['raw_sentiment', 'sentiment']].drop_duplicates().head(10)\n",
    "for _, row in mapping_examples.iterrows():\n",
    "    print(f\"{row['raw_sentiment']} → {row['sentiment']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped sentiment distribution:\n",
      "sentiment\n",
      "Neutral    7876\n",
      "Dovish      317\n",
      "Hawkish     104\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label mapping examples:\n",
      "neutral -> Neutral\n",
      "positive -> Hawkish\n",
      "negative -> Dovish\n",
      "Monthly index calculated for 74 months\n",
      "RoBERTa sentiment range: -0.985 to 0.999\n",
      "\n",
      "Saved detailed results to ../data/result/RoBERTa_Large/roberta_large_inference_results.csv\n",
      "Saved monthly index to ../data/result/RoBERTa_Large/monthly_index_RoBERTa_large.csv\n"
     ]
    }
   ],
   "source": [
    "# 5. Calculate Sentiment Index\n",
    "# Using score-based calculation: (Dovish_score - Hawkish_score) / count\n",
    "\n",
    "df['sentiment'] = df['raw_sentiment'].apply(get_sentiment_label_RoBERTa)\n",
    "\n",
    "print(\"Mapped sentiment distribution:\")\n",
    "print(df[\"sentiment\"].value_counts())\n",
    "\n",
    "# Show mapping examples\n",
    "print(\"\\nLabel mapping examples:\")\n",
    "mapping_examples = df[['raw_sentiment', 'sentiment']].drop_duplicates().head(10)\n",
    "for _, row in mapping_examples.iterrows():\n",
    "    print(f\"{row['raw_sentiment']} -> {row['sentiment']}\")\n",
    "\n",
    "# Calculate monthly sentiment index\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "\n",
    "# Apply score-based calculation\n",
    "monthly_index = df.groupby(\"month\", group_keys=False).apply(\n",
    "    calculate_net_sentiment_scores, include_groups=False\n",
    ").reset_index(name=\"sentiment_score\")\n",
    "\n",
    "monthly_index['month'] = monthly_index['month'].dt.to_timestamp()\n",
    "monthly_index = monthly_index.sort_values('month')\n",
    "\n",
    "print(f\"Monthly index calculated for {len(monthly_index)} months\")\n",
    "print(f\"RoBERTa sentiment range: {monthly_index['sentiment_score'].min():.3f} to {monthly_index['sentiment_score'].max():.3f}\")\n",
    "\n",
    "# Save results\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "monthly_index.to_csv(INDEX_OUTPUT_FILE, index=False)\n",
    "print(f\"\\nSaved detailed results to {OUTPUT_FILE}\")\n",
    "print(f\"Saved monthly index to {INDEX_OUTPUT_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
