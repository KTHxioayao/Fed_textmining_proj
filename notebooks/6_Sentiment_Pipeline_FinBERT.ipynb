{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "4f0ed3d7",
            "metadata": {},
            "source": [
                "# Sentiment Analysis Pipeline: FinBERT\n",
                "\n",
                "**Objective**: Apply `ZiweiChen/FinBERT` to the Fed Speeches dataset using a standardized pipeline.\n",
                "**Methodology**:\n",
                "1. **Load Data**: Processed sentences (`data/master/fed_master_corpus_focused.csv`).\n",
                "2. **Inference**: Classify each sentence as Hawkish, Dovish, or Neutral.\n",
                "3. **Index Calculation**: Compute Net Sentiment Index using the \"Score-based\" formula: $Index = \\frac{Hawkish_{score} - Dovish_{score}}{Total_{count}}$.\n",
                "4. **Aggregation**: Aggregate by Date/Meeting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "e4ab578c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Successfully imported utilities.\n",
                        "Using device: -1 (CPU) \n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
                "import torch\n",
                "from tqdm.auto import tqdm\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Ensure project root is in path for utils import\n",
                "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
                "if project_root not in sys.path:\n",
                "    sys.path.append(project_root)\n",
                "\n",
                "# Import custom utilities\n",
                "try:\n",
                "    from utils.utilities import calculate_net_sentiment_scores, calculate_net_sentiment_counts, get_sentiment_label_FinBERT_FOMC\n",
                "    print(\"Successfully imported utilities.\")\n",
                "except ImportError as e:\n",
                "    print(f\"Import Error: {e}. Please ensure 'utils' package is available.\")\n",
                "\n",
                "# Config\n",
                "MODEL_NAME = \"ProsusAI/finbert\"\n",
                "# Use the FOCUSED dataset (Data Clean 2)\n",
                "INPUT_FILE = \"../data/master/fed_master_corpus_focused.csv\"\n",
                "OUTPUT_FILE = \"../data/result/FinBERT/finbertori_inference_results.csv\"\n",
                "INDEX_OUTPUT_FILE = \"../data/result/FinBERT/monthly_index_FinBERTori_FOMC.csv\"\n",
                "\n",
                "# Set Device\n",
                "device = 0 if torch.cuda.is_available() else -1\n",
                "print(f\"Using device: {device} ({torch.cuda.get_device_name(0) if device==0 else 'CPU'}) \")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "0472ac10",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded 8297 sentences from FOCUSED dataset.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>date</th>\n",
                            "      <th>text</th>\n",
                            "      <th>section</th>\n",
                            "      <th>source</th>\n",
                            "      <th>speaker</th>\n",
                            "      <th>word_count</th>\n",
                            "      <th>month_year</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>2018-01-31</td>\n",
                            "      <td>The manager of the System Open Market Account ...</td>\n",
                            "      <td>Developments in Financial Markets</td>\n",
                            "      <td>Minutes</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>24</td>\n",
                            "      <td>2018-01</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2018-01-31</td>\n",
                            "      <td>Domestic financial market conditions eased con...</td>\n",
                            "      <td>Staff Review of Financial Situation</td>\n",
                            "      <td>Minutes</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>11</td>\n",
                            "      <td>2018-01</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>2018-01-31</td>\n",
                            "      <td>A strengthening outlook for economic growth in...</td>\n",
                            "      <td>Staff Review of Financial Situation</td>\n",
                            "      <td>Minutes</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>23</td>\n",
                            "      <td>2018-01</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>2018-01-31</td>\n",
                            "      <td>U.S. equity prices, Treasury yields, and marke...</td>\n",
                            "      <td>Staff Review of Financial Situation</td>\n",
                            "      <td>Minutes</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>31</td>\n",
                            "      <td>2018-01</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>2018-01-31</td>\n",
                            "      <td>In addition, the dollar depreciated broadly am...</td>\n",
                            "      <td>Staff Review of Financial Situation</td>\n",
                            "      <td>Minutes</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>29</td>\n",
                            "      <td>2018-01</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "         date                                               text  \\\n",
                            "0  2018-01-31  The manager of the System Open Market Account ...   \n",
                            "1  2018-01-31  Domestic financial market conditions eased con...   \n",
                            "2  2018-01-31  A strengthening outlook for economic growth in...   \n",
                            "3  2018-01-31  U.S. equity prices, Treasury yields, and marke...   \n",
                            "4  2018-01-31  In addition, the dollar depreciated broadly am...   \n",
                            "\n",
                            "                               section   source speaker  word_count month_year  \n",
                            "0    Developments in Financial Markets  Minutes     NaN          24    2018-01  \n",
                            "1  Staff Review of Financial Situation  Minutes     NaN          11    2018-01  \n",
                            "2  Staff Review of Financial Situation  Minutes     NaN          23    2018-01  \n",
                            "3  Staff Review of Financial Situation  Minutes     NaN          31    2018-01  \n",
                            "4  Staff Review of Financial Situation  Minutes     NaN          29    2018-01  "
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 1. Load Data\n",
                "if not os.path.exists(INPUT_FILE):\n",
                "    # Fallback paths\n",
                "    INPUT_FILE = r\"e:\\Textming\\data\\master\\fed_master_corpus.csv\"\n",
                "    \n",
                "df = pd.read_csv(INPUT_FILE)\n",
                "print(f\"Loaded {len(df)} sentences from FOCUSED dataset.\")\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "4a3fed14",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading model: ProsusAI/finbert...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Device set to use cpu\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model loaded successfully.\n"
                    ]
                }
            ],
            "source": [
                "# 2. Initialize Model Pipeline (Official Method)\n",
                "print(f\"Loading model: {MODEL_NAME}...\")\n",
                "try:\n",
                "    # Using BertForSequenceClassification with num_labels=3 per official guidance\n",
                "    tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
                "    model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
                "    nlp = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device, truncation=True, max_length=512)\n",
                "    print(\"Model loaded successfully.\")\n",
                "except Exception as e:\n",
                "    print(f\"ERROR Loading Model: {e}\")\n",
                "    # Stop execution or set flag\n",
                "    nlp = None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "10c9f384",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting Inference...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "bb032275da504383bb66171a1cf0649b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/260 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# 3. Run Inference\n",
                "BATCH_SIZE = 32\n",
                "sentences = df['text'].astype(str).tolist()\n",
                "results = []\n",
                "\n",
                "if nlp:\n",
                "    print(\"Starting Inference...\")\n",
                "    for i in tqdm(range(0, len(sentences), BATCH_SIZE)):\n",
                "        batch = sentences[i:i + BATCH_SIZE]\n",
                "        try:\n",
                "            preds = nlp(batch)\n",
                "            results.extend(preds)\n",
                "        except Exception as e:\n",
                "            print(f\"Error at batch {i}: {e}\")\n",
                "            results.extend([{'label': 'Neutral', 'score': 0.0}] * len(batch))\n",
                "else:\n",
                "    print(\"Model not loaded. Filling with Defaults (Neutral) for testing structure.\")\n",
                "    results = [{'label': 'Neutral', 'score': 0.0} for _ in sentences]\n",
                "\n",
                "# Attach results\n",
                "df['raw_sentiment'] = [x['label'] for x in results]\n",
                "df['sentiment_score'] = [x['score'] for x in results]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "5ffee38b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "raw_sentiment\n",
                        "neutral     3389\n",
                        "negative    2566\n",
                        "positive    2342\n",
                        "Name: count, dtype: int64\n",
                        "Mapped sentiment distribution:\n",
                        "sentiment\n",
                        "Neutral    3389\n",
                        "Dovish     2566\n",
                        "Hawkish    2342\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "Label mapping examples:\n",
                        "neutral -> Neutral\n",
                        "positive -> Hawkish\n",
                        "negative -> Dovish\n"
                    ]
                }
            ],
            "source": [
                "# 4. Map Labels\n",
                "# Using imported function: get_sentiment_label_FinBERT_FOMC\n",
                "\n",
                "print(df['raw_sentiment'].value_counts())\n",
                "\n",
                "# Map Labels to Fed Context\n",
                "df['sentiment'] = df['raw_sentiment'].apply(get_sentiment_label_FinBERT_FOMC)\n",
                "\n",
                "print(\"Mapped sentiment distribution:\")\n",
                "print(df['sentiment'].value_counts())\n",
                "\n",
                "# Show mapping examples\n",
                "print(\"\\nLabel mapping examples:\")\n",
                "mapping_examples = df[['raw_sentiment', 'sentiment']].drop_duplicates().head(10)\n",
                "for _, row in mapping_examples.iterrows():\n",
                "    print(f\"{row['raw_sentiment']} -> {row['sentiment']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "b4e20946",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved index to ../data/result/FinBERT/monthly_index_FinBERTori_FOMC.csv\n"
                    ]
                }
            ],
            "source": [
                "# 5. Calculate Sentiment Index (Score-based)\n",
                "# Formula: (avg Dovish score - avg Hawkish score)\n",
                "\n",
                "df['date'] = pd.to_datetime(df['date'])\n",
                "df['month'] = df['date'].dt.to_period('M')\n",
                "\n",
                "# Use calculate_net_sentiment_scores for Score-based method\n",
                "monthly_index = df.groupby('month').apply(calculate_net_sentiment_scores, include_groups=False).reset_index(name='sentiment_index')\n",
                "monthly_index['month'] = monthly_index['month'].dt.to_timestamp()\n",
                "\n",
                "# Save\n",
                "df.to_csv(OUTPUT_FILE, index=False)\n",
                "monthly_index.to_csv(INDEX_OUTPUT_FILE, index=False)\n",
                "print(f\"Saved index to {INDEX_OUTPUT_FILE}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "textmining",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
